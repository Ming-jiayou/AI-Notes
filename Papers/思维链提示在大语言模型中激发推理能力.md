Chain-of-Thought Prompting Elicits Reasoning in Large Language Models

链式思维提示激发大语言模型的推理能力  
Jason Wei、Xuezhi Wang、Dale Schuurmans、Maarten Bosma  
Brian Ichter、Fei Xia、Ed H. Chi、Quoc V. Le、Denny Zhou  
谷歌研究，大脑团队  
{jasonwei,dennyzhou}@google.com

摘要  

我们探讨了生成思维链（即一系列中间推理步骤）如何显著提升大型语言模型执行复杂推理的能力。特别是，我们展示了通过一种称为“思维链提示”的简单方法，这种推理能力会自然地出现在足够大的语言模型中：该方法仅需在提示中提供少量思维链示例作为示范。  

对三个大型语言模型的实验表明，思维链提示在算术、常识推理和符号推理等多种任务上均提升了模型表现，实证增益十分显著。例如，仅用八个思维链示例提示PaLM 540B模型，在GSM8K数学应用题基准上达到了最先进的准确率，甚至超越了经过微调并带有验证器的GPT-3模型。

![](image-12.png)

图1：思维链提示使大型语言模型能够处理复杂的算术、常识和符号推理任务。思维链推理过程已标出。

1 引言

最近，自然语言处理领域已被语言模型彻底革新（Peters 等，2018；Devlin 等，2019；Brown 等，2020，以及其他研究）。扩大语言模型的规模已被证明能带来多种优势，例如性能提升和样本效率提高（Kaplan 等，2020；Brown 等，2020，以及其他研究）。然而，仅靠扩大模型规模并未足以在诸如算术、常识推理和符号推理等具有挑战性的任务上实现高性能（Rae 等，2021）。

这项工作探讨了如何通过一种受两种想法启发的简单方法，激发大型语言模型的推理能力。首先，算术推理技术可以从生成通向最终答案的自然语言推理过程受益。先前的研究已通过从零开始训练（Ling 等，2017）或微调预训练模型（Cobbe 等，2021），使模型具备生成自然语言中间步骤的能力，此外还有使用形式语言而非自然语言的神经符号方法（Roy 和 Roth，2015；Chiang 和 Chen，2019；Amini 等，2019；Chen 等，2019）。其次，大型语言模型为通过提示实现上下文中的少样本学习带来了令人振奋的前景。也就是说，无需为每个新任务单独微调一个语言模型，只需用几个展示该任务的输入-输出示例“提示”模型即可。令人惊讶的是，这种方法已在多种简单的问答任务中取得了成功（Brown 等，2020）。

然而，上述两种方法都存在关键的局限性。对于基于推理增强的训练和微调方法而言，构建大量高质量的推理样本代价高昂，其复杂程度远超普通机器学习中所使用的简单输入-输出对。而对于Brown等人（2020）所使用的传统少样本提示方法，它在需要推理能力的任务上表现不佳，并且随着语言模型规模的扩大，其性能往往并未显著提升（Rae等，2021）。在本文中，我们以一种规避这些局限性的方式，融合了上述两种方法的优势。具体而言，我们探索了语言模型在给定由三元组（输入、思维链、输出）构成的提示时，执行少样本提示进行推理任务的能力。其中，“思维链”是一系列连贯的自然语言中间推理步骤，最终导向输出结果，我们将这种方法称为“思维链提示”。图1展示了一个示例提示。

我们在算术、常识和符号推理基准上进行了实证评估，结果表明，思维链提示法优于标准提示法，有时甚至显著优于后者。图2展示了一个这样的结果——在GSM8K数学应用题基准（Cobbe等，2021）上，使用PaLM 540B模型的思维链提示法大幅超越了标准提示法，并取得了新的最先进性能。仅依赖提示的方法之所以重要，是因为它无需大量训练数据，且单个模型检查点即可在不丧失通用性的情况下执行多种任务。本研究凸显了大型语言模型如何通过少量自然语言示例学习任务（与通过大规模训练数据自动学习输入与输出背后模式的做法形成对比）。

2 思维链提示法

在解决复杂的推理任务（如多步骤数学应用题）时，人们通常会审视自己的思维过程，将问题分解为多个中间步骤，并依次解决每个步骤，最后得出最终答案。例如：“珍妮给妈妈2朵花后，她还剩下10朵……接着她再给爸爸3朵后，就剩下7朵了……因此答案是7。”本文的目标是赋予语言模型生成类似思维链的能力——即生成一系列连贯的中间推理步骤，最终导向问题的正确答案。我们将证明，如果在少样本提示的示例中提供思维链推理的示范，足够大的语言模型就能够生成此类思维链。

图1展示了一个模型生成思维链以解决原本可能出错的数学文字题的例子。在这种情况下，思维链类似于一个解题过程，可以被解释为一种解答，但我们仍选择称之为“思维链”，以便更准确地体现其模仿逐步思考以得出答案的过程（此外，通常解答或解释是在最终答案之后才给出的（Narang 等，2020；Wiegreffe 等，2022；Lampinen 等，2022 等））。

思维链提示作为一种促进语言模型推理的方法，具有若干吸引人的特性：

1. 首先，原则上，思维链允许模型将多步问题分解为中间步骤，这意味着可以为需要更多推理步骤的问题分配额外的计算资源。

2. 其次，思维链为模型的行为提供了一个可解释的窗口，可以揭示其如何得出某一特定答案，并为调试推理路径中的错误提供机会（尽管完整刻画支撑答案的模型计算过程仍是一个开放性问题）。

3. 第三，思维链推理可应用于数学文字题、常识推理和符号操作等任务，且原则上可能适用于人类可通过语言解决的任何任务。

4. 最后，仅需在少样本提示的示例中包含思维链序列，即可在足够大的现成语言模型中轻松激发思维链推理。

在实证实验中，我们将观察思维链提示在算术推理（第3节）、常识推理（第4节）和符号推理（第5节）中的实用性。

3 算术推理

我们首先考虑如图1所示形式的数学应用题，这类问题用于衡量语言模型的算术推理能力。尽管对人类而言这些题目很简单，但语言模型在算术推理任务上常常表现不佳（Hendrycks 等，2021；Patel 等，2021，及其他研究）。值得注意的是，当将思维链提示方法应用于具有5400亿参数的语言模型时，其在多个任务上的表现可与专门微调的模型相媲美，甚至在具有挑战性的GSM8K基准测试中（Cobbe 等，2021）达到了新的领先水平。

3.1 实验设置

我们针对多种语言模型，在多个基准上探索思维链提示方法。

基准数据集。我们考虑以下五个数学应用题基准：（1）Cobbe 等人（2021）提出的 GSM8K 数学应用题基准；（2）Patel 等人（2021）提出的 SVAMP 数据集，包含结构多样的数学应用题；（3）Miao 等人（2020）提出的 ASDiv 数据集，包含多样化的数学应用题；（4）AQuA 数据集，包含代数应用题；以及（5）Koncel-Kedziorski 等人（2016）提出的 MAWPS 基准。示例问题见附录表12。

标准提示。作为基线方法，我们采用 Brown 等人（2020）推广的标准少样本提示方法：在模型对测试样本进行预测前，为其提供一些输入-输出对的示例。这些示例以“问题-答案”的形式呈现，模型直接输出答案，如图1（左侧）所示。

思维链提示。我们提出的方法是，在少样本提示中的每个示例旁增加一个与答案相关的思维链，如图1（右）所示。由于大多数数据集仅包含评估划分，我们手动构建了一组八个包含思维链的少样本示例用于提示——图1（右）展示了一个思维链示例，完整的示例集合见附录表20。（这些特定示例未经过提示工程优化；鲁棒性在第3.4节和附录A.2中进行研究。）为了探究这种形式的思维链提示是否能够成功激发模型在多种任务中的有效推理能力，在数学应用题中，我们为所有基准测试使用了同一组八个思维链示例，唯独AQuA除外，因为AQuA是选择题而非自由回答题。对于AQuA，我们使用了训练集中的四个示例及其解答，具体内容见附录表21。

语言模型。我们评估了五个大型语言模型。第一个是GPT-3（Brown等，2020），我们使用了text-ada-001、text-babbage-001、text-curie-001和text-davinci-002，这些模型推测对应于参数量分别为3.5亿、13亿、67亿和1750亿的InstructGPT模型（Ouyang等，2022）。第二个是LaMDA（Thoppilan等，2022），其模型参数量分别为4.22亿、20亿、80亿、680亿和1370亿。第三个是PaLM，其模型参数量为80亿、620亿和5400亿。第四个是UL2 20B（Tay等，2022）。第五个是Codex（Chen等，2021，OpenAI API中的code-davinci-002）。我们通过贪婪解码从这些模型中采样（尽管后续研究表明，通过从多次采样生成中取多数最终答案可改进思维链提示的效果（Wang等，2022a））。对于LaMDA，我们报告了五个随机种子的平均结果，每个种子对应的示例顺序均为随机打乱。由于LaMDA实验在不同种子间的差异较小，为节省计算资源，我们对其他所有模型仅报告单组示例顺序的结果。

3.2 结果  

思维链提示法的最强结果汇总于图4中，每个模型集合、模型规模和基准测试的全部实验输出详见附录中的表2。主要得出三个关键结论。首先，图4表明，思维链提示是一种随模型规模涌现的能力（Wei 等，2022b）。也就是说，对于小型模型，思维链提示并不会提升性能，只有在使用约1000亿参数规模的模型时，才会带来性能提升。我们定性发现，规模较小的模型虽然能生成流畅的思维链，但这些思维链缺乏逻辑性，导致其表现反而低于标准提示法。

其次，思维链提示在更复杂的问题上带来的性能提升更大。例如，在GSM8K（基线表现最低的数据集）上，最大规模的GPT和PaLM模型的性能提升超过了一倍。另一方面，在MAWPS中最简单的子集SingleOp上——该子集仅需单步推理即可解决——性能提升要么为负，要么非常微小（参见附录表3）。

第三，通过GPT-3 175B和PaLM 540B实施的思维链提示，在性能上优于此前的最先进方法——这些方法通常需要在有标签的训练数据集上对特定任务模型进行微调。图4展示了PaLM 540B如何通过思维链提示在GSM8K、SVAMP和MAWPS上达到新的最先进水平（请注意，标准提示法在SVAMP上已超越了此前的最佳表现）。在另外两个数据集AQuA和ASDiv上，应用思维链提示的PaLM模型性能已接近最先进水平，差距在2%以内（见附录表2）。

为了更好地理解思维链提示为何有效，我们手工检查了LaMDA 137B在GSM8K任务上生成的思维链。在50个模型最终答案正确的随机样本中，所有生成的思维链在逻辑和数学上均正确，仅有两例虽然答案正确，但推理过程存在偶然性错误（参见附录D.1及表8，以查看正确的模型生成思维链示例）。

我们还随机抽样了50个模型回答错误的样本进行分析。分析总结表明：46%的思维链几乎正确，仅存在微小错误（例如计算器使用错误、符号映射错误或缺少一个推理步骤）；其余54%的思维链则存在严重的语义理解或连贯性错误（参见附录D.2）。为了初步理解为何模型规模扩大能够提升思维链推理能力，我们对PaLM 62B模型产生的错误进行了类似分析，并考察了当模型扩展为PaLM 540B时这些错误是否被纠正。分析表明，将PaLM从62B扩展至540B显著修复了62B模型中大量缺失单步推理和语义理解方面的错误（参见附录A.1）。

3.3 消融研究  

使用思维链提示所观察到的性能提升，自然引发了一个问题：其他类型的提示是否也能带来相同的性能改进？图5展示了对三种思维链变体的消融研究，具体描述如下：  

仅使用方程。思维链提示可能有所帮助的一个原因是它生成了需要求解的数学方程，因此我们测试了一种变体：在给出答案前，仅提示模型输出一个数学方程。图5显示，仅使用方程的提示方法对GSM8K数据集的帮助很小，这表明GSM8K中问题的语义过于复杂，无法在没有思维链中自然语言推理步骤的情况下直接转化为方程。然而，对于一步或两步的问题集，我们发现仅使用方程的提示方法确实能提升性能，因为方程能够从问题中直接轻松推导出来（见附录表6）。

仅变量计算。另一种直观理解是，思维链使模型能够在更困难的问题上投入更多计算资源（即中间标记）。为了将变量计算的影响与思维链推理区分开来，我们测试了一种配置：模型被提示仅输出与求解问题所需方程字符数相等的省略号（...）。该变体的表现与基线几乎相同，这表明单纯的变量计算并不是思维链提示取得成功的原因，而通过自然语言表达中间步骤似乎具有实际效用。

答案之后的思维链。思维链提示可能带来的另一个潜在优势，仅仅是这类提示有助于模型更好地调用预训练阶段习得的相关知识。因此，我们测试了一种替代配置：仅在给出答案之后才提供思维链提示，以此分离出模型是否真正依赖于生成的思维链来得出最终答案。该变体的表现与基线几乎相同，这表明思维链所体现的序列化推理，其价值不仅在于激活知识，还在于其本身具有独立的作用。

3.4 思维链的鲁棒性

对示例的敏感性是提示方法中的关键考量因素——例如，改变少样本示例的排列方式，可能导致GPT-3在SST-2数据集上的准确率从接近随机水平（54.3%）提升至接近前沿水平（93.4%）（Zhao等，2021）。在本小节中，我们评估了由不同标注者撰写的思维链（chain of thought）对模型鲁棒性的影响。除了前述结果（这些结果使用的是标注者A编写的思维链）外，本文的另外两位合著者（标注者B和C）独立为相同的少样本示例撰写了思维链（见附录H）。标注者A还编写了另一条更简洁的思维链，其风格遵循Cobbe等（2021）所提供的解决方案风格。¹

图6展示了LaMDA 137B在GSM8K和MAWPS数据集上的这些结果（其他数据集的消融实验结果见附录表6/表7）。尽管不同思维链标注之间存在差异——这在意料之中，因为基于示例的提示本身就具有这种变异性（Le Scao和Rush，2021；Reynolds和McDonell，2021；Zhao等，2021）——但所有思维链提示均大幅超越了标准基线方法。这一结果表明，成功应用思维链提示并不依赖于特定的语言风格。

为验证成功的思维链提示在其他示例集合上同样有效，我们还使用从GSM8K训练集中随机抽取的三组各八个示例进行了实验，这些示例来自一个独立的数据源（该数据集中的示例已天然包含类似思维链的推理步骤）。² 图6显示，这些随机采样的提示在性能上与我们手动编写的示例相当，并且同样显著优于标准提示方法。

除了对标注者、独立撰写的思维链、不同示例以及多种语言模型的鲁棒性之外，我们还发现，在算术推理任务中，思维链提示对示例顺序和示例数量的变化也具有鲁棒性（详见附录A.2）。

4 常识推理

尽管思维链（chain of thought）特别适合数学应用题，但其基于语言的特性使其实际上可广泛应用于各类常识推理问题，这类问题涉及在拥有普遍背景知识的前提下，对物理现象和人类互动进行推理。常识推理对于与世界交互至关重要，但目前的自然语言理解系统仍未能完全掌握（Talmor 等，2021）。

基准测试集。我们选取了五个涵盖多样常识推理类型的公开数据集。广受欢迎的 CSQA（Talmor 等，2019）提出涉及复杂语义的常识性问题，通常需要先前知识。StrategyQA（Geva 等，2021）要求模型推导出多步策略来回答问题。我们从 BIG-bench 项目（BIG-bench 协作，2021）中选择了两个专门的评估集：Date Understanding，要求根据给定语境推断日期；Sports Understanding，要求判断与运动相关的句子是否合理。最后，SayCan 数据集（Ahn 等，2022）要求将自然语言指令映射为从离散动作集合中选取的一系列机器人操作。图 3 展示了所有数据集中带有思维链标注的示例。

提示构建方法。我们沿用上一节相同的实验设置。对于 CSQA 和 StrategyQA，我们从训练集中随机选取样本，并人工构造思维链作为少样本示例（few-shot exemplars）。而两个 BIG-bench 任务没有训练集，因此我们选取评估集中的前十个样例作为少样本示例，并在其余评估样本上报告性能结果。对于 SayCan，我们采用 Ahn 等（2022）所用训练集中的六个样本，并同样人工构造了思维链。

结果。图 7 展示了 PaLM 模型在这些任务上的结果（LaMDA、GPT-3 及不同规模模型的完整结果见表 4）。对于所有任务，增大模型规模都提升了标准提示方法的性能；而思维链提示进一步提升了效果，且在 PaLM 540B 上的增益最为显著。在思维链提示下，PaLM 540B 相比基线表现出强劲性能，在 StrategyQA 上超越此前最先进方法（75.6% 对比 69.4%），在运动理解任务中也超越了无辅助的体育爱好者（95.4% 对比 84%）。这些结果表明，思维链提示同样能显著提升需要多种常识推理能力的任务表现（尽管在 CSQA 上增益较小）。

5 符号推理

我们的最终实验评估聚焦于符号推理任务，这类任务对人类而言很简单，但对语言模型可能具有挑战性。我们表明，思维链提示不仅能帮助语言模型在标准提示设置下难以完成的符号推理任务中取得表现，还能促进模型在推理时对超出少样本示例长度的输入实现泛化。

**任务设计**：我们使用以下两个简化任务：

- **最后一个字母拼接**：该任务要求模型将名称中每个词的最后一个字母拼接起来（例如，“Amy Brown” → “yn”）。这是首个字母拼接任务的更复杂版本，而语言模型在没有思维链提示的情况下已能完成首个字母拼接。我们通过从姓名普查数据（https://namecensus.com/）中的前一千个常见姓氏和名字中随机组合生成完整姓名。

- **硬币翻转**：该任务要求模型判断在若干人选择翻转或不翻转硬币之后，硬币是否仍为正面朝上（例如，“一枚硬币正面朝上。Phoebe 翻转了硬币。Osvaldo 没有翻转硬币。硬币现在还是正面朝上吗？” → “no”）。

由于这些符号推理任务的结构定义清晰，我们为每个任务构建了“域内”测试集和“域外”（OOD）测试集。域内测试集中的示例步骤数与训练或少样本示例一致；而域外测试集中的示例步骤数则多于示例中的步骤数。在最后一个字母拼接任务中，模型仅在训练中见过由两个词组成的姓名示例，而在测试时需对包含三个和四个词的姓名执行最后一个字母拼接。我们对硬币翻转任务中潜在翻转次数的处理方式相同。

本实验的设置与前两节使用的方法和模型一致。我们手动为每个任务的少样本示例编撰了思维链提示，具体内容见图3。

**结果**：图8展示了PaLM模型在域内与域外测试中的表现，LaMDA的结果见附录表5。对于PaLM 540B模型，思维链提示使两个任务的正确率接近100%（值得注意的是，标准提示在PaLM 540B上已能解决硬币翻转任务，但在LaMDA 137B上不行）。需要指出的是，这些域内评估属于“玩具任务”，因为少样本示例中已提供了完美的解题步骤结构——模型只需在测试示例中复现相同步骤并替换为新的符号即可。即便如此，小规模模型仍表现不佳；只有当模型参数规模达到约100B级别时，才表现出对未见过符号进行抽象操作的能力。

对于域外测试，标准提示在两个任务上均完全失败。而采用思维链提示后，语言模型表现出明显的性能提升趋势（尽管表现仍低于域内设置）。这表明，对于足够大规模的语言模型，思维链提示能够实现对超出训练中所见思维链长度的推理输入进行泛化。

6 讨论

我们探讨了思维链提示作为一种简单机制，用于激发大型语言模型中的多步推理行为。首先，我们发现思维链提示在算术推理任务中显著提升了性能，其改进效果远超各种消融实验，并且对不同的标注者、示例和语言模型均表现出稳健性（第3节）。其次，关于常识推理的实验表明，思维链推理的语言本质使其具有广泛的适用性（第4节）。最后，我们证明了在符号推理任务中，思维链提示有助于模型在更长序列长度上实现分布外（OOD）泛化（第5节）。在所有实验中，思维链推理仅通过提示现成的语言模型即可被激发，整个研究过程中并未对任何语言模型进行微调。

思维链推理随着模型规模扩大而涌现，这已成为一个普遍现象（Wei等，2022b）。在许多标准提示方法表现出平缓缩放曲线的推理任务中，思维链提示却带来了显著陡峭的缩放曲线。思维链提示似乎扩展了大型语言模型所能成功完成的任务集——换言之，我们的研究强调，标准提示仅是大型语言模型能力的下界。这一观察很可能引发更多问题而非提供答案：例如，随着模型规模进一步增大，我们还能期望推理能力提升多少？还有哪些其他提示方法可以扩展语言模型可解决的任务范围？

关于局限性，我们首先指出，尽管思维链模拟了人类推理者的思维过程，但这并不能回答神经网络是否真正具有“推理”能力，我们对此保留为一个开放性问题。其次，尽管在少样本设置中手动为示例添加思维链的成本较低，但在微调场景下，这种标注成本可能变得极其高昂（尽管这或许可通过合成数据生成或零样本泛化加以缓解）。第三，思维链推理路径并不保证正确，因此可能产生正确或错误的答案；提升语言模型的事实生成准确性是未来研究的一个开放方向（Rashkin等，2021；Ye和Durrett，2022；Wiegreffe等，2022等）。最后，思维链推理仅在大规模模型中才会出现，这使得其在现实应用场景中的部署成本高昂；进一步的研究可探索如何在较小模型中诱导出推理能力。

7 相关工作

本研究受到多个研究领域的启发，我们在扩展的相关工作部分（附录C）中进行了详细阐述。此处，我们重点描述两个最相关的研究方向及其相关文献。

第一个相关方向是通过中间步骤来解决推理问题。Ling 等人（2017）率先提出使用自然语言推理过程来解决数学文字题，通过一系列中间步骤逐步推导答案。他们的工作与大量采用形式语言进行推理的研究形成了鲜明对比（Roy 等，2015；Chiang 和 Chen，2019；Amini 等，2019；Chen 等，2019）。Cobbe 等人（2021）在 Ling 等人（2017）的基础上，构建了更大规模的数据集，并利用该数据集对预训练语言模型进行微调，而非从头开始训练模型。在程序合成领域，Nye 等人（2021）利用语言模型，通过逐行预测 Python 程序的中间计算结果，从而推断出最终输出，并证明其逐步预测的方法优于直接预测最终结果。

当然，本文也与近期大量关于提示（prompting）的研究密切相关。自 Brown 等人（2020）普及了少样本提示方法以来，多种通用方法已显著提升了模型的提示能力，例如自动学习提示词（Lester 等，2021）或向模型提供描述任务的指令（Wei 等，2022a；Sanh 等，2022；Ouyang 等，2022）。这些方法主要改进或增强提示的输入部分（例如，附加在输入前的指令），而我们的工作则采取了一种对立的方向：通过引入思维链条（chain of thought）来增强语言模型的输出。

8 结论  

我们探讨了思维链提示作为一种简单且广泛应用的方法，用于增强语言模型的推理能力。通过在算术、符号和常识推理任务上的实验，我们发现，思维链推理是模型规模所涌现的特性，它使得足够大的语言模型能够执行那些原本具有平坦扩展曲线的推理任务。扩大语言模型所能执行的推理任务范围，有望进一步推动基于语言的推理方法的研究。

A 常见问题解答  

A.1 为什么增大模型规模能提升思维链提示的效果？

研究发现，成功的思维链推理仅在特定的模型规模下才会稳定出现，这一现象十分引人注目。已有研究表明，扩大语言模型的规模能带来性能提升和样本效率提高等优势（Kaplan 等，2020），但思维链推理具有“涌现性”特征——即其成功无法仅通过外推小模型的性能来预测，因为对于大多数参数少于100亿的模型而言，思维链反而会降低其表现。  

关于为什么模型规模的扩大能改善思维链提示，这一问题显然是多方面的。我们通过错误分析对此进行了初步探讨。该小型分析手工检查了PaLM 62B模型产生的45个错误，并将其归类为语义理解错误（20例）、步骤缺失（18例）和其他错误（7例）。“其他”类别包括幻觉、重复输出和符号映射错误。该分类方法借鉴了LaMDA初始错误分析（见附录D.2）中的粗糙分类，相关类别是基于使思维链推理得以修正所需实现的改进而设计的。

如图9所示，将PaLM扩展至540B参数后，三类错误中均有相当大比例被纠正。图10展示了PaLM扩展至540B后被修复的语义理解错误和步骤缺失错误的实例。这一结果似乎支持一个假设：随着模型规模的增大，语言模型会逐步获得一系列语义理解和逻辑推理能力（但需注意，模型规模经常与其他因素（如训练计算量）混为一谈）。

此外，关于小型语言模型为何失败，还有三个值得注意的要点。首先，小型语言模型甚至在相对简单的符号映射任务上也会失败。如第5节所示，即便是一些仅需基于少样本示例中提供的相同推理链条结构进行新示例泛化的符号推理任务，小型语言模型仍然无法完成。其次，小型语言模型在算术能力上似乎天生较弱；正如Brown等人（2020）所展示的，执行简单的算术运算（即使不需要语义理解）也需要足够大的模型规模。最后，我们定性地观察到，小型语言模型经常无法生成可被解析的最终答案，原因要么是重复输出，要么是推理过程始终未能得出结论。

总之，思维链推理的成功依赖于模型规模，这是一个复杂的现象，很可能涉及多种涌现能力（如语义理解、符号映射、保持主题、算术能力、忠实性等）。未来的研究可以更深入地探究哪些预训练数据、模型架构以及优化目标的特性在因果层面促成了此类推理能力的出现。

A.2 提示工程的作用是什么？

提示的一个关键考量是对提示语的精确性敏感。大量研究已经表明，提示会以意想不到的方式影响语言模型（Min 等，2022）。我们生成思维链标注的一般方法是从训练集中选取八个示例，并将推理过程分解为多个逐步推导出最终答案的步骤。图3中提供了思维链标注的示例，完整的提示见附录G。

为了分析思维链对提示工程的敏感性，我们针对多个因素进行了鲁棒性实验：

• 不同的标注者。我们首先分析了三种不同标注者带来的鲁棒性差异（见第3.4节与图6）。尽管性能存在明显差异（我们将在后文讨论），但在算术、常识与符号推理的八个数据集上，所有三位标注者生成的思维链标注均大幅优于基线方法（见表6与表7）。类似于Cobbe等人（2021）的标注流程，标注者并未获得关于如何撰写思维链标注的具体指导，仅被要求写出通向最终答案的逐步推理过程。因此，这些标注均体现了每位标注者自身的语言表达风格——即各自的“思维链”写作风格。

• 无机器学习背景的标注者。GSM8K数据集（Cobbe等，2021）提供了一个由众包工作者撰写的推理链训练集，这使我们能够探索：当使用来自非机器学习背景来源的推理链时，思维链方法是否依然有效。因此，我们从GSM8K中随机抽取了三组包含八条思维链的示例。这些思维链标注在全部四个算术数据集上均大幅优于基线（见表6），表明思维链方法并不依赖于特定的一组标注者。

• 不同的示例。上述使用不同GSM8K示例的实验（见表6）还表明，思维链提示对不同的示例集同样有效。值得注意的是，我们对所有四个算术数据集都使用了相同的一组示例（而非为每个数据集单独从其训练集中选取示例），这提示：示例不一定需要与测试样本来自相同的数据分布。

• 不同的示例顺序。先前研究已表明，在某些任务中（如分类），提示的排列顺序也会产生影响——对少量示例进行不同排列可能导致GPT-3在SST-2上的准确率从接近随机水平（54.3%）到接近当前最优水平（93.4%）不等（Zhao等，2021）。我们于表6和表7中展示了不同示例顺序带来的性能标准差。几乎所有情况下，提示顺序对性能的影响都极小。唯一的例外是“抛硬币”任务，其示例顺序的标准差较高，原因很可能如Zhao等（2021）所指出的那样：在分类任务中，连续出现多个相同类别的示例会偏差模型输出。

• 不同数量的示例。我们还发现，即使示例数量变化，思维链提示带来的收益依然保持稳定。图11展示了五个数据集上的结果（由于计算资源限制，我们未在全部数据集上运行该实验）。初步实验还表明，在标准提示中进一步增加示例数量（如从8个增至16个）并不能带来显著性能提升，甚至不足以使标准提示赶上思维链提示的表现。

• 不同的语言模型。另一个有趣的问题是：对某个模型有效的提示，是否也对其他大型语言模型更有效？我们发现，在使用相同提示的前提下，思维链提示显著提升了所有三个模型（LaMDA、GPT-3和PaLM）在所有数据集上的表现，仅在GPT-3上的CSQA和StrategyQA两个数据集上例外（见表1、表4、表5）。然而，思维链带来的收益未能在不同模型间完全迁移，是一个局限性；未来研究可进一步探讨不同预训练数据集和模型架构如何影响思维链提示的增益效果。

尽管如此，提示工程仍然至关重要。虽然在算术推理任务中，结果对提示相对鲁棒，但我们必须明确指出：在许多情况下，提示工程依然能显著提升性能。尽管大多数思维链标注均优于标准提示，但各案例中的性能差异依然巨大。例如，在“抛硬币”任务中，标注者A的性能达到99.6%，而标注者C仅为71.4%，尽管两者均远高于基线（50.0%）（见表7）。甚至存在一些任务，提示工程是实现良好表现的必要条件：在初步实验中，我们尝试使用思维链提示让语言模型反转一个包含五项内容的列表顺序。尽管两位合作者尽最大努力仍未能写出能够成功解决该任务的思维链提示，但第三位合作者却成功设计出了一个完美解决该任务的思维链。

如何以一种鲁棒的方式自动生成思维链标注，将是未来研究的一个有趣方向。例如，一个潜在的思路是：借助大型语言模型本身，通过提示自动生成思维链（并可能在验证集上对生成过程进行优化）。

A.3 链式思维提示是否能改善我所关注任务的性能？

虽然链式思维提示在原则上适用于任何文本到文本的任务，但它对某些任务的帮助比其他任务更大。基于本文的实验，我们的直觉是，当满足以下三个条件时，链式思维提示的效果最为显著：(1) 任务具有挑战性，需要多步推理；(2) 使用了大型语言模型；(3) 模型的扩展曲线相对平缓。相反，如果上述任一条件不满足，链式思维提示带来的收益则会较小。

这些直觉或许可以从算术推理的结果中得到支持。在GSM8K（具有挑战性的多步问题，且扩展曲线平缓）上，PaLM 540B 从链式思维提示中获得的性能提升最大，这刚好符合上述三个条件。而在仅需一步或两步推理的MAWPS子集（SingleOP、SingleEq 和 AddSub）上，性能提升则很小，这是因为PaLM 540B 在这些任务上已能达到90%或更高的准确率（并且通常而言，当性能已经很强时，进一步提升的空间也较小）。

尽管本文主要聚焦于多步推理任务（算术、常识和符号推理），但链式思维提示原则上可以应用于任何人类在解决时会使用“链式思维”的任务。我们将链式思维提示在更多样化任务（例如机器翻译等）中的实证评估留待未来研究。

A.4 为什么仅使用方程作为提示不足以应对某些算术推理数据集？

仅以方程作为中间步骤进行提示，在许多数据集上确实有一定帮助，特别是当这些数据集仅需要少量推理步骤时（如 SVAMP、ASDiv、MAWPS）。然而，对于 GSM8K 数据集，仅使用方程并未显著提升模型性能。基于定性分析，我们认为这些题目在语义上过于复杂，模型难以直接将其翻译为数学方程。

以 LaMDA 137B 的一个示例为例：

问题：迈克打了 40 分钟乒乓球。在前 20 分钟里，他得了 4 分；在后 20 分钟里，他多得了 25% 的分数。他总共得了多少分？

仅用方程（错误答案）：(4 + 20 * 0.25) = 6。答案是 6。

思维链（正确答案）：迈克打了 40 分钟乒乓球。在前 20 分钟里，他得了 4 分。在后 20 分钟里，他多得了 25% 的分数。因此，他在后 20 分钟的得分比前 20 分钟多了 25%。4 × 1.25 = 5。所以他在后 20 分钟得了 5 分。因此，他总共得了 9 分。答案是 9。

模型难以直接将所有语义内容精准地转化为单一的数学方程，而思维链方法则允许它通过自然语言的中间步骤，逐步推理并理解问题的各个部分，从而更有效地得出正确答案。
